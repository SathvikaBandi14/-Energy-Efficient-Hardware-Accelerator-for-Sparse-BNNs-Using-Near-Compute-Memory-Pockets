# -*- coding: utf-8 -*-
"""iiitb2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IEa2VARSpGvc52MyyduydYVCcVfEGmTo
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Function

class StraightThrough(Function):
    @staticmethod
    def forward(ctx, input):
        return torch.sign(input)
    @staticmethod
    def backward(ctx, grad_output):
        # Straight-Through Estimator (STE)
        return grad_output

binary_sign = StraightThrough.apply

class BinaryConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):
        super().__init__()
        self.in_channels = in_channels
        self.stride = stride
        self.padding = padding
        # weights MUST have requires_grad=True
        # Better initialization range (-1 to 1)
        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-1, 1), requires_grad=True)
        self.bn = nn.BatchNorm2d(out_channels) # BatchNorm is essential

    def forward(self, x):
        input_real = binary_sign(x)
        wb = binary_sign(self.weight)

        output = F.conv2d(input_real, wb, stride=self.stride, padding=self.padding)

        # BinaryNet Scaling
        scale = (self.weight.shape[2] * self.weight.shape[3] * self.in_channels) ** (-0.5)
        output = output * scale

        return self.bn(output)

class BinaryLinear(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.in_features = in_features
        self.weight = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-1, 1), requires_grad=True)
        self.bn = nn.BatchNorm1d(out_features)

    def forward(self, x):
        if len(x.shape) > 2:
            x = x.view(x.size(0), -1)
        input_real = binary_sign(x)
        wb = binary_sign(self.weight)

        output = F.linear(input_real, wb)
        output = output * (self.in_features ** (-0.5))
        return self.bn(output)

class BNN(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = BinaryConv2d(1, 32, 3, padding=1)
        self.conv2 = BinaryConv2d(32, 64, 3, padding=1)
        self.conv3 = BinaryConv2d(64, 128, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout2d(0.3)

        # Auto compute flatten size
        dummy = torch.zeros(1, 1, 28, 28)
        with torch.no_grad():
            x = self.pool(torch.relu(self.conv1(dummy)))
            x = self.pool(torch.relu(self.conv2(x)))
            x = self.pool(torch.relu(self.conv3(x)))  # 3rd conv
            self.flatten_size = int(x.numel() / x.shape[0])

        print(f"Flatten size: {self.flatten_size}")
        self.fc1 = BinaryLinear(self.flatten_size, 256)
        self.fc2 = BinaryLinear(256, num_classes)

    def forward(self, x):
        x = torch.relu(self.pool(self.conv1(x)))
        x = self.dropout(x)
        x = torch.relu(self.pool(self.conv2(x)))
        x = self.dropout(x)
        x = torch.relu(self.pool(self.conv3(x)))
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Data Preparation (MNIST)
transform = transforms.Compose([
    transforms.ToTensor(),# Scales pixels from [0, 255] to [0, 1]
    transforms.Normalize((0.1307,), (0.3081,))# Centers data so mean is 0 [Subtracts the mean (0.1307) and divides by the standard deviation (0.3081).]
])

train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Data Preparation (MNIST)
transform = transforms.Compose([
    transforms.ToTensor(),# Scales pixels from [0, 255] to [0, 1]
    transforms.Normalize((0.1307,), (0.3081,))# Centers data so mean is 0 [Subtracts the mean (0.1307) and divides by the standard deviation (0.3081).]
])

train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

# Model Initialization
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = BNN().to(device)

# Using a standard Learning Rate for BNNs
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# Training Loop with BNN Guardrails
print(f"Starting Training on {device} for 50 Epochs...")

for epoch in range(50):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)

        if torch.isnan(loss):
            continue

        loss.backward()

        # Gradient Clipping to prevent NaNs
        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        optimizer.step()

        # Weight Clipping (ESSENTIAL for BNN)
        # shadow weights sensitive so they can flip between -1 and +1
        with torch.no_grad():
            for name, param in model.named_parameters():
                if 'weight' in name:
                    param.clamp_(-1, 1)

        # Statistics
        running_loss += loss.item()
        _, predicted = output.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()

    # Evaluation Phase
    model.eval()
    test_correct = 0
    test_total = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            _, predicted = output.max(1)
            test_total += target.size(0)
            test_correct += predicted.eq(target).sum().item()

    train_acc = 100. * correct / total
    test_acc = 100. * test_correct / test_total

    print(f"Epoch {epoch+1}: Loss: {running_loss/len(train_loader):.4f} | "
          f"Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%")

print("\n Training Complete!")

import torch

model_path = "bnn_mnist_final_12th.pth"

# Save the state_dict
torch.save(model.state_dict(), model_path)

print(f"Model weights saved to {model_path}")

from google.colab import files

# Download to your local PC
files.download("bnn_mnist_final_12th.pth")

import matplotlib.pyplot as plt
import numpy as np

def visualize_binarization(model, dataset):
    # 1. Get a single image
    img, label = dataset[21339]

    # 2. Normalize and Binarize
    # Add batch dimension [1, 1, 28, 28]
    img_input = img.unsqueeze(0)
    # Use your custom binary_sign function
    img_binarized = binary_sign(img_input)

    # 3. Plotting
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # Raw Tensor (Scaled 0 to 1 by ToTensor)
    axes[0].imshow(img.squeeze(), cmap='gray')
    axes[0].set_title("1. Normalized Input\n(Floating Point)")

    # Binarized (-1 and 1)
    axes[1].imshow(img_binarized.squeeze().numpy(), cmap='bwr') # Blue-White-Red
    axes[1].set_title("2. Binarized Input\n(-1 = Blue, 1 = Red)")

    # Histogram to prove it's only two values
    axes[2].hist(img_binarized.view(-1).numpy(), bins=10, color='purple')
    axes[2].set_title("3. Pixel Value Distribution\n(Binary Check)")
    axes[2].set_xlabel("Value")
    axes[2].set_ylabel("Pixel Count")

    plt.tight_layout()
    plt.show()

# Run it
visualize_binarization(model, train_dataset)

import random

def gallery_check(model, dataset):
    for _ in range(5):
        idx = random.randint(0, len(dataset)-1)
        print(f"Checking Index: {idx}")
        visualize_prediction(model, dataset, index=idx)

gallery_check(model, test_dataset)

"""## PRUNING"""

# Initialize the architecture
model = BNN()

# Load the state dict
# map_location ensures it loads correctly even if you switch from GPU to CPU
model.load_state_dict(torch.load("/content/bnn_mnist_final_12th.pth", map_location=torch.device('cpu')))

# Move to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval() # Set to evaluation mode for testing

print("Model successfully loaded and ready for pruning!")

import torch
import torch.nn as nn

def prune_bnn_channels(model, checkpoint_path, pruning_percentile=0.15):
    # Load the trained weights
    model.load_state_dict(torch.load(checkpoint_path))
    model.eval()

    print(f"Starting pruning (Target: {pruning_percentile*100}% reduction)...")

    with torch.no_grad():
        for name, module in model.named_modules():
            # prune based on BatchNorm gamma (weight)
            if isinstance(module, nn.BatchNorm2d):
                gamma = module.weight.data.abs()

                # Determine the threshold for this specific layer
                threshold = torch.quantile(gamma, pruning_percentile)

                # Create a binary mask (1 for keep, 0 for prune)
                mask = (gamma > threshold).float()

                # Apply mask to Gamma and Bias
                module.weight.data *= mask
                module.bias.data *= mask

                # Identify how many channels survived
                survived = int(mask.sum().item())
                total = len(mask)
                print(f"Layer: {name} | Kept {survived}/{total} channels")

    # Save the pruned model
    torch.save(model.state_dict(), "bnn_pruned_initial.pth")
    return model

"""## gradual fine tuning"""

def fine_tune_pruned_model(model, train_loader, test_loader, epochs=10):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # Low LR is critical
    criterion = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # CRITICAL: Keep pruned channels at zero after every step
            with torch.no_grad():
                for m in model.modules():
                    if isinstance(m, nn.BatchNorm2d):
                        m.weight.data[m.weight.data == 0] = 0
                        m.bias.data[m.weight.data == 0] = 0

            # BNN Maintenance: Clip shadow weights
            for param in model.parameters():
                if param.dim() > 1: param.clamp_(-1, 1)

def fine_tune_pruned_model(model, train_loader, test_loader, epochs=10, save_path="pruned_finetuned.pth"):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Low LR is critical
    criterion = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # CRITICAL: Keep pruned channels at zero
            with torch.no_grad():
                for m in model.modules():
                    if isinstance(m, nn.BatchNorm2d):
                        mask = (m.weight.data == 0)
                        m.weight.data[mask] = 0
                        m.bias.data[mask] = 0

            # BNN Maintenance: Clip shadow weights
            for param in model.parameters():
                if param.dim() > 1:
                    param.clamp_(-1, 1)

            running_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}")

save_path = "/content/pruned_finetuned_model.pth"
torch.save(model.state_dict(), save_path)

print("Model saved at:", save_path)

model.eval()
correct = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / len(test_dataset)
print(f"Current Accuracy after Fine-tuning: {accuracy:.2f}%")

def export_for_vitis(model, filename="params.h"):
    with open(filename, 'w') as f:
        f.write("#ifndef PARAMS_H\n#define PARAMS_H\n#include <ap_int.h>\n\n")

        for name, m in model.named_modules():
            if isinstance(m, nn.BatchNorm2d):
                # 1. Export Binarized Weights (+1 -> 1, -1 -> 0)
                # Linking BN to its Conv layer
                conv_name = name.split('.bn')[0]
                weights = dict(model.named_parameters())[f"{conv_name}.weight"].data
                bin_weights = (torch.sign(weights) + 1) / 2

                # 2. Step (a): Extract indices of unpruned channels
                mask = (m.weight.data != 0).cpu().numpy()
                indices = np.where(mask)[0]

                f.write(f"// Data for {conv_name}\n")
                f.write(f"const ap_uint<1> {conv_name}_weights[] = {{{', '.join(map(str, bin_weights.flatten().int().tolist()))}}};\n")
                f.write(f"const uint16_t {conv_name}_indices[] = {{{', '.join(map(str, indices))}}};\n")

                # 3. Folded Threshold Logic for Step (b)
                # Logic: threshold = mean - (bias * std / gamma)
                std = torch.sqrt(m.running_var + m.eps)
                thresh = m.running_mean - (m.bias.data * std / m.weight.data)
                f.write(f"const int {conv_name}_thresholds[] = {{{', '.join(map(lambda x: str(int(x)), thresh.tolist()))}}};\n\n")

        f.write("#endif")
    print(f"Successfully exported to {filename}")

import torch
import numpy as np
import os

def export_week1_sparse(model, filename="sparse_params.h"):
    # 1. Ensure model is in eval mode and on CPU
    model.eval()
    model.cpu()

    with open(filename, 'w') as f:
        f.write("#ifndef SPARSE_PARAMS_H\n#define SPARSE_PARAMS_H\n")
        f.write("#include <ap_int.h>\n\n")
        f.write("typedef ap_uint<1> bit;\n\n")

        # Global PTR array starts at 0
        current_ptr = 0

        for name, m in model.named_modules():
            if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):
                conv_name = name.split('.bn')[0].replace('.', '_')
                weights = dict(model.named_parameters())[f"{name.split('.bn')[0]}.weight"].data

                # Step (a): Pruning - Find unpruned channel indices
                mask = (m.weight.data != 0).cpu().numpy()
                active_indices = np.where(mask)[0]

                # Step (b): Binarization - Convert to 1 and 0 (for ap_uint<1>)
                pruned_weights = weights[active_indices]
                bin_weights = (torch.sign(pruned_weights) + 1) / 2
                bin_list = bin_weights.flatten().int().tolist()

                # Step (c/d): Memory Pocket Constants
                f.write(f"// --- {conv_name} CSR Representation ---\n")
                f.write(f"const int {conv_name}_VAL[] = {{{', '.join(map(str, bin_list))}}};\n")
                f.write(f"const uint16_t {conv_name}_COL[] = {{{', '.join(map(str, active_indices))}}};\n")
                f.write(f"const int {conv_name}_num_active = {len(active_indices)};\n\n")

        f.write("#endif\n")

    print(f"Week 1 Logic Exported: {os.path.abspath(filename)}")

# Run it!
export_week1_sparse(model)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def plot_confusion(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())

    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix: Where is the model failing?')
    plt.show()

plot_confusion(model, test_loader)

def check_errors(model, dataset, num_samples=10):
    model.eval()
    errors = 0
    plt.figure(figsize=(15, 6))

    # We loop through random indices to find mistakes
    indices = list(range(len(dataset)))
    random.shuffle(indices)

    count = 0
    for idx in indices:
        if count >= num_samples: break

        img, label = dataset[idx]
        img_input = img.unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(img_input)
            _, pred = torch.max(output, 1)
            pred = pred.item()

        if pred != label:
            count += 1
            plt.subplot(2, 5, count)
            # Display binarized image (Hardware view)
            plt.imshow(img.squeeze(), cmap='gray')
            plt.title(f"Idx: {idx}\nExp: {label} | Pred: {pred}", color='red')
            plt.axis('off')

    plt.tight_layout()
    plt.show()

check_errors(model, test_dataset)

import random
import matplotlib.pyplot as plt
import torch

def check_random_gallery(model, dataset, num_samples=10):
    # Set model to evaluation mode
    model.eval()
    device = next(model.parameters()).device

    plt.figure(figsize=(15, 6))

    # Select 'num_samples' unique random indices from the dataset
    indices = random.sample(range(len(dataset)), num_samples)

    for i, idx in enumerate(indices):
        img, label = dataset[idx]
        # Prepare image for the model (add batch dimension and move to device)
        img_input = img.unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(img_input)
            _, pred = torch.max(output, 1)
            pred = pred.item()

        # Determine color based on accuracy
        is_correct = (pred == label)
        color = 'green' if is_correct else 'red'
        status = "Correct" if is_correct else "Error"

        # Plotting
        plt.subplot(2, 5, i + 1)
        # Use squeeze() to remove channel dim for grayscale display
        plt.imshow(img.squeeze(), cmap='gray')
        plt.title(f"Index: {idx}\nExp: {label} | Pred: {pred}\n({status})", color=color, fontsize=10)
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Execute the check on your test dataset
check_random_gallery(model, test_dataset)